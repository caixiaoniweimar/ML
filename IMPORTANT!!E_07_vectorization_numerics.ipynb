{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class exercise 7: Deep Learning (Part 1A)\n",
    "In this notebook we will see how to write efficient and numerically stable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "# Scale each feature to [-1, 1] range\n",
    "X = minmax_scale(X, feature_range=(-1, 1))\n",
    "X.shape, y.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Logistic regression (two classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting:** Logistic regression (two classes)\n",
    "\n",
    "**Task:** Generate predictions for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]   #D from N*D\n",
    "w = np.random.normal(size=[n_features], scale=0.1)  # weight vector\n",
    "b = np.random.normal(size=[1])  # bias\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"Apply sigmoid to the input array.\"\"\"    \n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad - for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_loop(X, w, b):\n",
    "    \"\"\"Generate predictions with a logistic regression model using a for-loop.\n",
    "    \n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        w: weights vector, shape (D)\n",
    "        b: bias term, shape (1)\n",
    "        \n",
    "    Returns:\n",
    "        y: probabilies of the positive class, shape (N)\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    y = np.zeros([n_samples])\n",
    "    for i in range(n_samples):\n",
    "        score = np.dot(X[i], w) + b\n",
    "        y[i] = sigmoid(score)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (30,), (1,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, w.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X@w).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good - vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_vectorized(X, w, b):\n",
    "    \"\"\"Generate predictions with a logistic regression model using vectorized operations.\n",
    "    \n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        w: weights vector, shape (D)\n",
    "        b: bias term, shape (1)\n",
    "        \n",
    "    Returns:\n",
    "        y: probabilies of the positive class, shape (N)\n",
    "    \"\"\"\n",
    "    scores = X @ w + b   #shape(n_samples)\n",
    "    y = sigmoid(scores)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the runtime of two variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.92 ms ± 99 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predict_for_loop(X, w, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.9 µs ± 331 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predict_vectorized(X, w, b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. K-nearest neighbors\n",
    "A more complicated task: compute the matrix of pairwise distances.\n",
    "\n",
    "Given a data matrix `X` of size `[N, D]`, compute the matrix `dist` of pairwise distances of size `[N, N]`, where `dist[i, j] = l2_distance(X[i], X[j])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad - for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_distance(x, y):\n",
    "    \"\"\"Compute Euclidean distance between two vectors.\"\"\"\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_for_loop(X):\n",
    "    \"\"\"Compute pairwise distances between all instances (for loop version).\n",
    "    \n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        \n",
    "    Returns:\n",
    "        dist: matrix of pairwise distances, shape (N, N)\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    distances = np.zeros([n_samples, n_samples])\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            distances[i, j] = l2_distance(X[i], X[j])\n",
    "    return distances\n",
    "\n",
    "#O(|N|^2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 569)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist1 = distances_for_loop(X)\n",
    "dist1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good - vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we compute all the distances in a vectorized way?\n",
    "\n",
    "Start with a simpler example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(5, dtype=np.float64)\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape([-1,1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -2., -3., -4.],\n",
       "       [ 1.,  0., -1., -2., -3.],\n",
       "       [ 2.,  1.,  0., -1., -2.],\n",
       "       [ 3.,  2.,  1.,  0., -1.],\n",
       "       [ 4.,  3.,  2.,  1.,  0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape([-1,1]) - x.reshape([1, -1]) #x.reshape([-1, 1]) boardcast to [5,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boardcasting equal to\n",
    "x.reshape([-1,1]).repeat(5, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape([1,-1]).repeat(5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn x-shape(5,) to shape(5,1)\n",
    "x2 = np.arange(5)\n",
    "x2.shape\n",
    "x2[:, None].shape #-> shape(5,1) \n",
    "x2[:, np.newaxis].shape#all entry at the 0-axis and for the first axis, add an additional dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the dimension of an array using `np.newaxis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.],\n",
       "       [-1.,  0.,  1.,  2.,  3.],\n",
       "       [-2., -1.,  0.,  1.,  2.],\n",
       "       [-3., -2., -1.,  0.,  1.],\n",
       "       [-4., -3., -2., -1.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[np.newaxis, :] - x[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_vectorized(X):\n",
    "    \"\"\"Compute pairwise distances between all instances (vectorized version).\n",
    "    \n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        \n",
    "    Returns:\n",
    "        dist: matrix of pairwise distances, shape (N, N)\n",
    "    \"\"\"\n",
    "    return np.sqrt(((X[:, None] - X[None, :])**2).sum(-1))\n",
    "\n",
    "\n",
    "def distances_vectorized2(X):\n",
    "    \"\"\"Compute pairwise distances between all instances (vectorized version).\n",
    "    \n",
    "    Args:\n",
    "        X: data matrix, shape (N, D)\n",
    "        \n",
    "    Returns:\n",
    "        dist: matrix of pairwise distances, shape (N, N)\n",
    "    \"\"\"\n",
    "    return np.sqrt(((X - X)**2).sum(-1))\n",
    "#sum(-1) take the rightest dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 1, 30)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, None,:].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 1, 30)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 569, 30)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[None, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 569, 30)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[:, None,:]-X[None,:,:]).shape #N*N*D   #[i,j,k] = X[i,k]-X[j,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 569, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((X[:, None] - X[None, :]).shape)\n",
    "y1=((X[:, None] - X[None, :])**2).sum(-1)\n",
    "y2=((X[:, None] - X[None, :])**2).sum(2)\n",
    "np.all(y1==y2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 569)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2 = distances_vectorized(X)\n",
    "dist22 = distances_vectorized2(X)\n",
    "np.all(dist2==dist22)\n",
    "dist2.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that both variants produce the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direct comparison fails because of tiny numerical differences\n",
    "np.all(dist1 == dist2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.382806063356817e-14"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two results are very close\n",
    "np.linalg.norm(dist1 - dist2, ord='fro')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use np.allclose to compare\n",
    "np.allclose(dist1, dist2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best - library function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "# Compute distance between each pair of the two collections of inputs\n",
    "# 两个矩阵行间的所有向量对的距离\n",
    "dist3 = cdist(X, X)\n",
    "# pdist:Pairwise distances between observations in n-dimensional space.\n",
    "# 所有向量间的距离\n",
    "dist4 = squareform(pdist(X))  #every pari of points\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(dist3==dist4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(dist3==dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1201143480289869e-13"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(dist2-dist3, ord='fro') #Frobenius norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.19 s ± 55.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dist1 = distances_for_loop(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.4 ms ± 1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dist2 = distances_vectorized(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.47 ms ± 44.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dist3 = cdist(X, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.43 ms ± 28.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dist4 = squareform(pdist(X))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons:\n",
    "1. For-loops are extremely slow! Avoid them whenever possible.\n",
    "2. A better alternative - use matrix operations & broadcasting\n",
    "3. An even better alternative - use library functions (if they are available).\n",
    "4. Implementations with for-loops can be useful for debugging vectorized code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Numerical stability\n",
    "Typically, GPUs use single precision (32bit) floating point numbers (in some cases even half precision / 16bit). This significantly speeds ups the computations, but also makes numerical issues a lot more likely. \n",
    "Because of this we always have to be extremely careful to implement our code in a numerically stable way.\n",
    "\n",
    "Most commonly, numerical issues occur when dealing with `log` and `exp` functions (e.g. when computing cross-entropy of a categorical distribution) and `sqrt` for values close to zero (e.g. when computing standard deviations or normalizing the $L_2$ norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Avoiding numerical overflow (exploding `exp`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function $f : \\mathbb{R}^D \\to \\Delta^{D - 1}$ converts a vector $\\mathbf{x} \\in \\mathbb{R}^D$ into a vector of probabilities.\n",
    "\n",
    "$$f(\\mathbf{x})_j = \\frac{\\exp(x_j)}{\\sum_{d=1}^{D} \\exp(x_d)}$$\n",
    "\n",
    "Apply the softmax function to the following vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0., 4., 5).astype(np.float32)#numpy.linspace(start, stop, num=50)\n",
    "x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01165623, 0.03168492, 0.08612855, 0.23412167, 0.6364086 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our code here\n",
    "denominator=np.exp(x).sum()\n",
    "np.exp(x) / denominator\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply it to the following vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50., 60., 70., 80., 90.], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(50., 90., 5).astype(np.float32)\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.1847055e+21, 1.1420074e+26, 2.5154387e+30, 5.5406225e+34,\n",
       "                 inf], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0., nan], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our code here\n",
    "denominator = np.exp(x).sum()\n",
    "np.exp(x) / denominator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to avoid the exposion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.248161e-18, 9.357198e-14, 2.061060e-09, 4.539787e-05,\n",
       "       9.999546e-01], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shifted = x - np.max(x)\n",
    "denominator = np.exp(x_shifted).sum()\n",
    "np.exp(x_shifted) / denominator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Working in the log-space / simplifying the expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary cross entropy (BCE) loss for a logistic regression model (corresponds to negative log-likelihood of a Bernoulli model)\n",
    "\n",
    "$$\\log p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}, b) = -\\sum_{i=1}^{N} y_i \\log \\sigma(\\mathbf{w}^T \\mathbf{x}_i + b) + (1 - y_i) \\log (1 - \\sigma(\\mathbf{w}^T \\mathbf{x}_i + b))$$\n",
    "\n",
    "\n",
    "Implement the BCE computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def binary_cross_entropy_unstable(scores, labels):\n",
    "    return -labels * np.log(sigmoid(scores)) - (1 - labels) * np.log(1 - sigmoid(scores))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[20., 20.]])  #shape (1,2)\n",
    "w = np.array([[1., 1.]])\n",
    "y = np.array([1.])\n",
    "\n",
    "scores = x @ w.T\n",
    "binary_cross_entropy_unstable(scores, y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-inf]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1-sigmoid(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/xiao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-y)*np.log(1-sigmoid(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to simplify the BCE loss as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "def binary_cross_entropy_stable(scores, labels):\n",
    "    return np.log(1 + np.exp(scores)) - labels * scores\n",
    "\n",
    "\n",
    "\n",
    "binary_cross_entropy_stable(scores, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Loss of numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the log sigmoid function \n",
    "\n",
    "$$f(x) = \\log \\sigma(x) = \\log \\left(\\frac{1}{1 + \\exp(-x)}\\right) = log 1 -log(1+exp(-x))=-log(1+exp(-x))$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def log_sigmoid_unstable(x):\n",
    "    return np.log(1 / (1 + np.exp(-x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`float32` has much lower \"resolution\" than `float64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.9314718e-01, -4.8587345e-02, -2.4756414e-03, -1.2338923e-04,\n",
       "       -6.1989022e-06, -3.5762793e-07,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 30, 11).astype(np.float32) #can only present a small fraction of the numbers\n",
    "log_sigmoid_unstable(x)\n",
    "#less accurate prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.93147181e-01, -4.85873516e-02, -2.47568514e-03, -1.23402190e-04,\n",
       "       -6.14419348e-06, -3.05902274e-07, -1.52299796e-08, -7.58256125e-10,\n",
       "       -3.77513576e-11, -1.87960758e-12, -9.34807787e-14])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 30, 11).astype(np.float64)\n",
    "log_sigmoid_unstable(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the log-sigmoid function in a numerically stable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sigmoid_stable(x):\n",
    "    return -np.log1p(np.exp(-x)) #log1p: log(1 + x)\n",
    "\n",
    "#better then -np.log(1+np.exp(-x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.9314718e-01, -4.8587348e-02, -2.4756852e-03, -1.2340219e-04,\n",
       "       -6.1441933e-06, -3.0590226e-07, -1.5229979e-08, -7.5825607e-10,\n",
       "       -3.7751344e-11, -1.8795289e-12, -9.3576229e-14], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 30, 11).astype(np.float32)\n",
    "log_sigmoid_stable(x)\n",
    "#more accurate but using single precision float\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log1p? #log(1 + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant functions: `np.log1p`, `np.expm1`, `scipy.special.logsumexp`, `scipy.special.softmax` -- these are also implemented in all major deep learning frameworks.\n",
    "\n",
    "`np.exmp1`: Calculate exp(x) - 1 for all elements in the array \n",
    "\n",
    "`scipy.special.logsumexp`: Compute the log of the sum of exponentials of input elements.\n",
    "\n",
    "`scipy.special.softmax` : softmax(x) = np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "different types of numerical instability: underflow and overflow, if we try to exponentiate by the very large or samll numbers.\n",
    "\n",
    "always try to simply the loss function \n",
    "\n",
    "softmax function: substract the maximum value to avoid overflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons:\n",
    "1. Be especially careful when working with `log` and `exp` functions in **single precision** floating point arithmetics\n",
    "2. Work in the log-space when possible\n",
    "3. Use numerically stable library functions when available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}