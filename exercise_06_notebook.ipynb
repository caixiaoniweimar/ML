{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Programming assignment 3: Optimization - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this notebook code skeleton for performing logistic regression with gradient descent is given. \n",
    "Your task is to complete the functions where required. \n",
    "You are only allowed to use built-in Python functions, as well as any `numpy` functions. No other libraries / imports are allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For numerical reasons, we actually minimize the following loss function\n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N} NLL(\\mathbf{w}) +  \\frac{1}{2}\\lambda ||\\mathbf{w}||^2_2$$\n",
    "\n",
    "where $NLL(\\mathbf{w})$ is the negative log-likelihood function, as defined in the lecture (see  Eq. 33)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exporting the results to PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once you complete the assignments, export the entire notebook as PDF and attach it to your homework solutions. \n",
    "The best way of doing that is\n",
    "1. Run all the cells of the notebook.\n",
    "2. Export/download the notebook as PDF (File -> Download as -> PDF via LaTeX (.pdf)).\n",
    "3. Concatenate your solutions for other tasks with the output of Step 2. On a Linux machine you can simply use `pdfunite`, there are similar tools for other platforms too. You can only upload a single PDF file to Moodle.\n",
    "\n",
    "Make sure you are using `nbconvert` Version 5.5 or later by running `jupyter nbconvert --version`. Older versions clip lines that exceed page width, which makes your code harder to grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load and preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this assignment we will work with the UCI ML Breast Cancer Wisconsin (Diagnostic) dataset https://goo.gl/U2Uwz2.\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. There are 212 malignant examples and 357 benign examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n",
      "[1. 1. 1. 1. 1.]\n",
      "15\n",
      "[1 0 1 0 1 1 0 1 1]\n",
      "(2, 2)\n",
      "(1, 2)\n",
      "(2, 1)\n",
      "[[10]]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Add a vector of ones to the data matrix to absorb the bias term\n",
    "X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "\n",
    "# Set the random seed so that we have reproducible experiments\n",
    "np.random.seed(123)\n",
    "\n",
    "# Split into train and test\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "arr = np.array([1, 2, 3,4,5])\n",
    "arr3 = np.array([1,2])\n",
    "print(arr[arr3])\n",
    "print(np.ones(arr.shape))\n",
    "print(arr.sum())\n",
    "print(y_test[1:10])\n",
    "\n",
    "arr2 = np.array([[1,2],[3,4]])\n",
    "print(arr2.shape)\n",
    "print(arr2[0].reshape(1,2).shape)\n",
    "print(arr2[:,1:].shape)\n",
    "print(np.matmul(arr2[0].reshape(1,2),arr2[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task 1: Implement the sigmoid function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid function elementwise to the input data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t : array, arbitrary shape\n",
    "        Input data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    t_sigmoid : array, arbitrary shape.\n",
    "        Data after applying the sigmoid function.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    result = 1/(1+np.exp(-t))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task 2: Implement the negative log likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As defined in Eq. 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def negative_log_likelihood(X, y, w):\n",
    "    \"\"\"\n",
    "    Negative Log Likelihood of the Logistic Regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        (Augmented) feature matrix.\n",
    "    y : array, shape [N]\n",
    "        Classification targets.\n",
    "    w : array, shape [D]\n",
    "        Regression coefficients (w[0] is the bias term).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        The negative log likelihood.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    exp_Xw = np.exp(X.dot(w)) #N*D * D*1 = N*1\n",
    "    y_ones = np.ones(y.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    result = -y.T.dot(X.dot(w)) + np.sum(np.log(exp_Xw+1))\n",
    "    \n",
    "    #result = 0\n",
    "    #for i in range(len(y)):  #CHECK!!!!\n",
    "    #    a=w.T.dot(X[i])\n",
    "    #    print(a.shape)\n",
    "    #    result += -y[i]*(w.T.dot(X[i])) + np.log(1+np.exp(w.T.dot(X[i])))\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Computing the loss function $\\mathcal{L}(\\mathbf{w})$ (nothing to do here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(X, y, w, lmbda):\n",
    "    \"\"\"\n",
    "    Negative Log Likelihood of the Logistic Regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        (Augmented) feature matrix.\n",
    "    y : array, shape [N]\n",
    "        Classification targets.\n",
    "    w : array, shape [D]\n",
    "        Regression coefficients (w[0] is the bias term).\n",
    "    lmbda : float\n",
    "        L2 regularization strength.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        Loss of the regularized logistic regression model.\n",
    "    \"\"\"\n",
    "    # The bias term w[0] is not regularized by convention\n",
    "    return negative_log_likelihood(X, y, w) / len(y) + lmbda * 0.5 * np.linalg.norm(w[1:])**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task 3: Implement the gradient $\\nabla_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make sure that you compute the gradient of the loss function $\\mathcal{L}(\\mathbf{w})$ (not simply the NLL!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_gradient(X, y, w, mini_batch_indices, lmbda):\n",
    "    \"\"\"\n",
    "    Calculates the gradient (full or mini-batch) of the negative log likelilhood w.r.t. w.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        (Augmented) feature matrix.\n",
    "    y : array, shape [N]\n",
    "        Classification targets.\n",
    "    w : array, shape [D]\n",
    "        Regression coefficients (w[0] is the bias term).\n",
    "    \n",
    "    mini_batch_indices: array, shape [mini_batch_size]\n",
    "        The indices of the data points to be included in the (stochastic) calculation of the gradient.\n",
    "        This includes the full batch gradient as well, if mini_batch_indices = np.arange(n_train).\n",
    "    lmbda: float\n",
    "        Regularization strentgh. lmbda = 0 means having no regularization.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dw : array, shape [D]\n",
    "        Gradient w.r.t. w.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    #adjust X and y to the size of the mini batch\n",
    "    #print(mini_batch_indices)\n",
    "    \n",
    "    X = X[mini_batch_indices]\n",
    "    y = y[mini_batch_indices]\n",
    "    \n",
    "    exp_Xw = np.exp(X.dot(w))  #->[N]\n",
    "\n",
    "    result = (-X.T.dot(y)+X.T.dot(exp_Xw/(exp_Xw+1)))/mini_batch_indices.shape[0]\n",
    "\n",
    "    result += lmbda*w\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train the logistic regression model (nothing to do here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, num_steps, learning_rate, mini_batch_size, lmbda, verbose):\n",
    "    \"\"\"\n",
    "    Performs logistic regression with (stochastic) gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        (Augmented) feature matrix.\n",
    "    y : array, shape [N]\n",
    "        Classification targets.\n",
    "    num_steps : int\n",
    "        Number of steps of gradient descent to perform.\n",
    "    learning_rate: float\n",
    "        The learning rate to use when updating the parameters w.\n",
    "    mini_batch_size: int\n",
    "        The number of examples in each mini-batch.\n",
    "        If mini_batch_size=n_train we perform full batch gradient descent. \n",
    "    lmbda: float\n",
    "        Regularization strentgh. lmbda = 0 means having no regularization.\n",
    "    verbose : bool\n",
    "        Whether to print the loss during optimization.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    w : array, shape [D]\n",
    "        Optimal regression coefficients (w[0] is the bias term).\n",
    "    trace: list\n",
    "        Trace of the loss function after each step of gradient descent.\n",
    "    \"\"\"\n",
    "    \n",
    "    trace = [] # saves the value of loss every 50 iterations to be able to plot it later\n",
    "    n_train = X.shape[0] # number of training instances\n",
    "    \n",
    "    w = np.zeros(X.shape[1]) # initialize the parameters to zeros\n",
    "    \n",
    "    # run gradient descent for a given number of steps\n",
    "    for step in range(num_steps):\n",
    "        permuted_idx = np.random.permutation(n_train) # shuffle the data\n",
    "        \n",
    "        # go over each mini-batch and update the paramters\n",
    "        # if mini_batch_size = n_train we perform full batch GD and this loop runs only once\n",
    "        for idx in range(0, n_train, mini_batch_size):\n",
    "            # get the random indices to be included in the mini batch\n",
    "            mini_batch_indices = permuted_idx[idx:idx+mini_batch_size]\n",
    "            gradient = get_gradient(X, y, w, mini_batch_indices, lmbda)\n",
    "\n",
    "            # update the parameters\n",
    "            w = w - learning_rate * gradient\n",
    "        \n",
    "        # calculate and save the current loss value every 50 iterations\n",
    "        if step % 50 == 0:\n",
    "            loss = compute_loss(X, y, w, lmbda)\n",
    "            trace.append(loss)\n",
    "            # print loss to monitor the progress\n",
    "            if verbose:\n",
    "                #print(loss)\n",
    "                print('Step {0}, loss = {1:.4f}'.format(step, loss))\n",
    "    return w, trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task 4: Implement the function to obtain the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N_test, D]\n",
    "        (Augmented) feature matrix.\n",
    "    w : array, shape [D]\n",
    "        Regression coefficients (w[0] is the bias term).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : array, shape [N_test]\n",
    "        A binary array of predictions.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "#     pred = X.dot(w)\n",
    "#     result = pred>0\n",
    "#     return result.astype(int)\n",
    "\n",
    "    probs = sigmoid(X.dot(w))\n",
    "    probs[probs>0.5] = 1\n",
    "    probs[probs<=0.5] = 0\n",
    "    return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Full batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Change this to True if you want to see loss values over iterations.\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, loss = 0.7427\n",
      "Step 50, loss = 0.9390\n",
      "Step 100, loss = 0.5168\n",
      "Step 150, loss = 0.3869\n",
      "Step 200, loss = 0.3676\n",
      "Step 250, loss = 0.3523\n",
      "Step 300, loss = 0.3396\n",
      "Step 350, loss = 0.3290\n",
      "Step 400, loss = 0.3198\n",
      "Step 450, loss = 0.3119\n",
      "Step 500, loss = 0.3050\n",
      "Step 550, loss = 0.2988\n",
      "Step 600, loss = 0.2934\n",
      "Step 650, loss = 0.2884\n",
      "Step 700, loss = 0.2840\n",
      "Step 750, loss = 0.2799\n",
      "Step 800, loss = 0.2763\n",
      "Step 850, loss = 0.2729\n",
      "Step 900, loss = 0.2698\n",
      "Step 950, loss = 0.2669\n",
      "Step 1000, loss = 0.2642\n",
      "Step 1050, loss = 0.2618\n",
      "Step 1100, loss = 0.2595\n",
      "Step 1150, loss = 0.2574\n",
      "Step 1200, loss = 0.2554\n",
      "Step 1250, loss = 0.2535\n",
      "Step 1300, loss = 0.2518\n",
      "Step 1350, loss = 0.2501\n",
      "Step 1400, loss = 0.2486\n",
      "Step 1450, loss = 0.2471\n",
      "Step 1500, loss = 0.2458\n",
      "Step 1550, loss = 0.2445\n",
      "Step 1600, loss = 0.2432\n",
      "Step 1650, loss = 0.2421\n",
      "Step 1700, loss = 0.2410\n",
      "Step 1750, loss = 0.2399\n",
      "Step 1800, loss = 0.2389\n",
      "Step 1850, loss = 0.2380\n",
      "Step 1900, loss = 0.2371\n",
      "Step 1950, loss = 0.2362\n",
      "Step 2000, loss = 0.2354\n",
      "Step 2050, loss = 0.2346\n",
      "Step 2100, loss = 0.2339\n",
      "Step 2150, loss = 0.2332\n",
      "Step 2200, loss = 0.2325\n",
      "Step 2250, loss = 0.2318\n",
      "Step 2300, loss = 0.2312\n",
      "Step 2350, loss = 0.2306\n",
      "Step 2400, loss = 0.2300\n",
      "Step 2450, loss = 0.2295\n",
      "Step 2500, loss = 0.2289\n",
      "Step 2550, loss = 0.2284\n",
      "Step 2600, loss = 0.2279\n",
      "Step 2650, loss = 0.2275\n",
      "Step 2700, loss = 0.2270\n",
      "Step 2750, loss = 0.2266\n",
      "Step 2800, loss = 0.2261\n",
      "Step 2850, loss = 0.2257\n",
      "Step 2900, loss = 0.2253\n",
      "Step 2950, loss = 0.2249\n",
      "Step 3000, loss = 0.2246\n",
      "Step 3050, loss = 0.2242\n",
      "Step 3100, loss = 0.2239\n",
      "Step 3150, loss = 0.2235\n",
      "Step 3200, loss = 0.2232\n",
      "Step 3250, loss = 0.2229\n",
      "Step 3300, loss = 0.2226\n",
      "Step 3350, loss = 0.2223\n",
      "Step 3400, loss = 0.2220\n",
      "Step 3450, loss = 0.2217\n",
      "Step 3500, loss = 0.2214\n",
      "Step 3550, loss = 0.2212\n",
      "Step 3600, loss = 0.2209\n",
      "Step 3650, loss = 0.2206\n",
      "Step 3700, loss = 0.2204\n",
      "Step 3750, loss = 0.2202\n",
      "Step 3800, loss = 0.2199\n",
      "Step 3850, loss = 0.2197\n",
      "Step 3900, loss = 0.2195\n",
      "Step 3950, loss = 0.2193\n",
      "Step 4000, loss = 0.2191\n",
      "Step 4050, loss = 0.2189\n",
      "Step 4100, loss = 0.2187\n",
      "Step 4150, loss = 0.2185\n",
      "Step 4200, loss = 0.2183\n",
      "Step 4250, loss = 0.2181\n",
      "Step 4300, loss = 0.2179\n",
      "Step 4350, loss = 0.2177\n",
      "Step 4400, loss = 0.2175\n",
      "Step 4450, loss = 0.2174\n",
      "Step 4500, loss = 0.2172\n",
      "Step 4550, loss = 0.2170\n",
      "Step 4600, loss = 0.2169\n",
      "Step 4650, loss = 0.2167\n",
      "Step 4700, loss = 0.2166\n",
      "Step 4750, loss = 0.2164\n",
      "Step 4800, loss = 0.2163\n",
      "Step 4850, loss = 0.2161\n",
      "Step 4900, loss = 0.2160\n",
      "Step 4950, loss = 0.2158\n",
      "Step 5000, loss = 0.2157\n",
      "Step 5050, loss = 0.2156\n",
      "Step 5100, loss = 0.2154\n",
      "Step 5150, loss = 0.2153\n",
      "Step 5200, loss = 0.2152\n",
      "Step 5250, loss = 0.2151\n",
      "Step 5300, loss = 0.2149\n",
      "Step 5350, loss = 0.2148\n",
      "Step 5400, loss = 0.2147\n",
      "Step 5450, loss = 0.2146\n",
      "Step 5500, loss = 0.2145\n",
      "Step 5550, loss = 0.2144\n",
      "Step 5600, loss = 0.2142\n",
      "Step 5650, loss = 0.2141\n",
      "Step 5700, loss = 0.2140\n",
      "Step 5750, loss = 0.2139\n",
      "Step 5800, loss = 0.2138\n",
      "Step 5850, loss = 0.2137\n",
      "Step 5900, loss = 0.2136\n",
      "Step 5950, loss = 0.2135\n",
      "Step 6000, loss = 0.2134\n",
      "Step 6050, loss = 0.2133\n",
      "Step 6100, loss = 0.2132\n",
      "Step 6150, loss = 0.2131\n",
      "Step 6200, loss = 0.2130\n",
      "Step 6250, loss = 0.2129\n",
      "Step 6300, loss = 0.2128\n",
      "Step 6350, loss = 0.2128\n",
      "Step 6400, loss = 0.2127\n",
      "Step 6450, loss = 0.2126\n",
      "Step 6500, loss = 0.2125\n",
      "Step 6550, loss = 0.2124\n",
      "Step 6600, loss = 0.2123\n",
      "Step 6650, loss = 0.2122\n",
      "Step 6700, loss = 0.2122\n",
      "Step 6750, loss = 0.2121\n",
      "Step 6800, loss = 0.2120\n",
      "Step 6850, loss = 0.2119\n",
      "Step 6900, loss = 0.2118\n",
      "Step 6950, loss = 0.2118\n",
      "Step 7000, loss = 0.2117\n",
      "Step 7050, loss = 0.2116\n",
      "Step 7100, loss = 0.2115\n",
      "Step 7150, loss = 0.2114\n",
      "Step 7200, loss = 0.2114\n",
      "Step 7250, loss = 0.2113\n",
      "Step 7300, loss = 0.2112\n",
      "Step 7350, loss = 0.2112\n",
      "Step 7400, loss = 0.2111\n",
      "Step 7450, loss = 0.2110\n",
      "Step 7500, loss = 0.2109\n",
      "Step 7550, loss = 0.2109\n",
      "Step 7600, loss = 0.2108\n",
      "Step 7650, loss = 0.2107\n",
      "Step 7700, loss = 0.2107\n",
      "Step 7750, loss = 0.2106\n",
      "Step 7800, loss = 0.2105\n",
      "Step 7850, loss = 0.2105\n",
      "Step 7900, loss = 0.2104\n",
      "Step 7950, loss = 0.2103\n"
     ]
    }
   ],
   "source": [
    "n_train = X_train.shape[0]\n",
    "w_full, trace_full = logistic_regression(X_train, \n",
    "                                         y_train, \n",
    "                                         num_steps=8000, \n",
    "                                         learning_rate=1e-5, \n",
    "                                         mini_batch_size=n_train, \n",
    "                                         lmbda=0.1,\n",
    "                                         verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, loss = 1.3392\n",
      "Step 50, loss = 0.3214\n",
      "Step 100, loss = 0.2859\n",
      "Step 150, loss = 0.2555\n",
      "Step 200, loss = 0.2583\n",
      "Step 250, loss = 0.2407\n",
      "Step 300, loss = 0.2287\n",
      "Step 350, loss = 0.2272\n",
      "Step 400, loss = 0.2222\n",
      "Step 450, loss = 0.2237\n",
      "Step 500, loss = 0.2221\n",
      "Step 550, loss = 0.2309\n",
      "Step 600, loss = 0.2157\n",
      "Step 650, loss = 0.2168\n",
      "Step 700, loss = 0.2145\n",
      "Step 750, loss = 0.2180\n",
      "Step 800, loss = 0.2122\n",
      "Step 850, loss = 0.2342\n",
      "Step 900, loss = 0.2111\n",
      "Step 950, loss = 0.2140\n",
      "Step 1000, loss = 0.2105\n",
      "Step 1050, loss = 0.2163\n",
      "Step 1100, loss = 0.2093\n",
      "Step 1150, loss = 0.2086\n",
      "Step 1200, loss = 0.2091\n",
      "Step 1250, loss = 0.2114\n",
      "Step 1300, loss = 0.2101\n",
      "Step 1350, loss = 0.2071\n",
      "Step 1400, loss = 0.2078\n",
      "Step 1450, loss = 0.2064\n",
      "Step 1500, loss = 0.2061\n",
      "Step 1550, loss = 0.2092\n",
      "Step 1600, loss = 0.2166\n",
      "Step 1650, loss = 0.2065\n",
      "Step 1700, loss = 0.2134\n",
      "Step 1750, loss = 0.2070\n",
      "Step 1800, loss = 0.2049\n",
      "Step 1850, loss = 0.2100\n",
      "Step 1900, loss = 0.2039\n",
      "Step 1950, loss = 0.2248\n",
      "Step 2000, loss = 0.2060\n",
      "Step 2050, loss = 0.2180\n",
      "Step 2100, loss = 0.2028\n",
      "Step 2150, loss = 0.2052\n",
      "Step 2200, loss = 0.2074\n",
      "Step 2250, loss = 0.2080\n",
      "Step 2300, loss = 0.2019\n",
      "Step 2350, loss = 0.2040\n",
      "Step 2400, loss = 0.2127\n",
      "Step 2450, loss = 0.2060\n",
      "Step 2500, loss = 0.2016\n",
      "Step 2550, loss = 0.2013\n",
      "Step 2600, loss = 0.2126\n",
      "Step 2650, loss = 0.2024\n",
      "Step 2700, loss = 0.2050\n",
      "Step 2750, loss = 0.2064\n",
      "Step 2800, loss = 0.2000\n",
      "Step 2850, loss = 0.2074\n",
      "Step 2900, loss = 0.1997\n",
      "Step 2950, loss = 0.2157\n",
      "Step 3000, loss = 0.1997\n",
      "Step 3050, loss = 0.1998\n",
      "Step 3100, loss = 0.2021\n",
      "Step 3150, loss = 0.2119\n",
      "Step 3200, loss = 0.2046\n",
      "Step 3250, loss = 0.1985\n",
      "Step 3300, loss = 0.1983\n",
      "Step 3350, loss = 0.2023\n",
      "Step 3400, loss = 0.1994\n",
      "Step 3450, loss = 0.2036\n",
      "Step 3500, loss = 0.2076\n",
      "Step 3550, loss = 0.2109\n",
      "Step 3600, loss = 0.1975\n",
      "Step 3650, loss = 0.2200\n",
      "Step 3700, loss = 0.1985\n",
      "Step 3750, loss = 0.1984\n",
      "Step 3800, loss = 0.1980\n",
      "Step 3850, loss = 0.2021\n",
      "Step 3900, loss = 0.1988\n",
      "Step 3950, loss = 0.2152\n",
      "Step 4000, loss = 0.2016\n",
      "Step 4050, loss = 0.1963\n",
      "Step 4100, loss = 0.2036\n",
      "Step 4150, loss = 0.1965\n",
      "Step 4200, loss = 0.1978\n",
      "Step 4250, loss = 0.2101\n",
      "Step 4300, loss = 0.1964\n",
      "Step 4350, loss = 0.1957\n",
      "Step 4400, loss = 0.2229\n",
      "Step 4450, loss = 0.1960\n",
      "Step 4500, loss = 0.2022\n",
      "Step 4550, loss = 0.1953\n",
      "Step 4600, loss = 0.1955\n",
      "Step 4650, loss = 0.1952\n",
      "Step 4700, loss = 0.2042\n",
      "Step 4750, loss = 0.1973\n",
      "Step 4800, loss = 0.1973\n",
      "Step 4850, loss = 0.1949\n",
      "Step 4900, loss = 0.1954\n",
      "Step 4950, loss = 0.1953\n",
      "Step 5000, loss = 0.1981\n",
      "Step 5050, loss = 0.1944\n",
      "Step 5100, loss = 0.2009\n",
      "Step 5150, loss = 0.1944\n",
      "Step 5200, loss = 0.1987\n",
      "Step 5250, loss = 0.2079\n",
      "Step 5300, loss = 0.2014\n",
      "Step 5350, loss = 0.1951\n",
      "Step 5400, loss = 0.1960\n",
      "Step 5450, loss = 0.1981\n",
      "Step 5500, loss = 0.1938\n",
      "Step 5550, loss = 0.1990\n",
      "Step 5600, loss = 0.1949\n",
      "Step 5650, loss = 0.1983\n",
      "Step 5700, loss = 0.1938\n",
      "Step 5750, loss = 0.1937\n",
      "Step 5800, loss = 0.1939\n",
      "Step 5850, loss = 0.2032\n",
      "Step 5900, loss = 0.1937\n",
      "Step 5950, loss = 0.1948\n",
      "Step 6000, loss = 0.1932\n",
      "Step 6050, loss = 0.1929\n",
      "Step 6100, loss = 0.1952\n",
      "Step 6150, loss = 0.1928\n",
      "Step 6200, loss = 0.2002\n",
      "Step 6250, loss = 0.1925\n",
      "Step 6300, loss = 0.1925\n",
      "Step 6350, loss = 0.1985\n",
      "Step 6400, loss = 0.1944\n",
      "Step 6450, loss = 0.1958\n",
      "Step 6500, loss = 0.1930\n",
      "Step 6550, loss = 0.1937\n",
      "Step 6600, loss = 0.1921\n",
      "Step 6650, loss = 0.2048\n",
      "Step 6700, loss = 0.1996\n",
      "Step 6750, loss = 0.1968\n",
      "Step 6800, loss = 0.1973\n",
      "Step 6850, loss = 0.1956\n",
      "Step 6900, loss = 0.1925\n",
      "Step 6950, loss = 0.1916\n",
      "Step 7000, loss = 0.1991\n",
      "Step 7050, loss = 0.1915\n",
      "Step 7100, loss = 0.1916\n",
      "Step 7150, loss = 0.2028\n",
      "Step 7200, loss = 0.1913\n",
      "Step 7250, loss = 0.1926\n",
      "Step 7300, loss = 0.1916\n",
      "Step 7350, loss = 0.1951\n",
      "Step 7400, loss = 0.1913\n",
      "Step 7450, loss = 0.1920\n",
      "Step 7500, loss = 0.1910\n",
      "Step 7550, loss = 0.1915\n",
      "Step 7600, loss = 0.1945\n",
      "Step 7650, loss = 0.1948\n",
      "Step 7700, loss = 0.1982\n",
      "Step 7750, loss = 0.1926\n",
      "Step 7800, loss = 0.1911\n",
      "Step 7850, loss = 0.1925\n",
      "Step 7900, loss = 0.1906\n",
      "Step 7950, loss = 0.1950\n"
     ]
    }
   ],
   "source": [
    "n_train = X_train.shape[0]\n",
    "w_minibatch, trace_minibatch = logistic_regression(X_train, \n",
    "                                                   y_train, \n",
    "                                                   num_steps=8000, \n",
    "                                                   learning_rate=1e-5, \n",
    "                                                   mini_batch_size=50, \n",
    "                                                   lmbda=0.1,\n",
    "                                                   verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our reference solution produces, but don't worry if yours is not exactly the same. \n",
    "\n",
    "    Full batch: accuracy: 0.9240, f1_score: 0.9384\n",
    "    Mini-batch: accuracy: 0.9415, f1_score: 0.9533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1.]\n",
      "Full batch: accuracy: 0.9240, f1_score: 0.9384\n",
      "Mini-batch: accuracy: 0.9415, f1_score: 0.9533\n"
     ]
    }
   ],
   "source": [
    "y_pred_full = predict(X_test, w_full)\n",
    "print(y_pred_full)\n",
    "y_pred_minibatch = predict(X_test, w_minibatch)\n",
    "\n",
    "print('Full batch: accuracy: {:.4f}, f1_score: {:.4f}'\n",
    "      .format(accuracy_score(y_test, y_pred_full), f1_score(y_test, y_pred_full)))\n",
    "print('Mini-batch: accuracy: {:.4f}, f1_score: {:.4f}'\n",
    "      .format(accuracy_score(y_test, y_pred_minibatch), f1_score(y_test, y_pred_minibatch)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15, 10])\n",
    "plt.plot(trace_full, label='Full batch')\n",
    "plt.plot(trace_minibatch, label='Mini-batch')\n",
    "plt.xlabel('Iterations * 50')\n",
    "plt.ylabel('Loss $\\mathcal{L}(\\mathbf{w})$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}